# üöÄ Kubernetes Reliability and Resilience Checklist

## **1Ô∏è‚É£ Verify the Number of Replicas for Each Deployment**

### **üîç How to Check**
```sh
kubectl get deployments -A -o custom-columns="NAMESPACE:.metadata.namespace,NAME:.metadata.name,REPLICAS:.spec.replicas,AVAILABLE:.status.availableReplicas"
```
For a specific namespace:
```sh
kubectl get deployments -n <namespace>
```

### **‚úÖ How to Improve**
- Ensure at least **two replicas** for high availability.
- Use **Horizontal Pod Autoscaler (HPA)**:
  ```yaml
  apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    name: my-app-hpa
    namespace: my-namespace
  spec:
    minReplicas: 2
    maxReplicas: 10
    metrics:
      - type: Resource
        resource:
          name: cpu
          targetAverageUtilization: 70
  ```
- Use **Karpenter for auto-scaling node capacity**.

### **‚ö†Ô∏è Reliability Concerns**
- If **replicas = 1**, failure means downtime.
- Improper **HPA settings** may lead to over/under-scaling.

---

## **2Ô∏è‚É£ Validate Karpenter Auto-Scaling Configuration**

### **üîç How to Check**
```sh
kubectl get pods -n karpenter
kubectl get provisioners -A
```
Check logs for Karpenter issues:
```sh
kubectl logs -l app.kubernetes.io/name=karpenter -n karpenter
```

### **‚úÖ How to Improve**
- Ensure Karpenter **automatically provisions nodes**:
  ```yaml
  apiVersion: karpenter.k8s.aws/v1alpha5
  kind: Provisioner
  metadata:
    name: default
  spec:
    requirements:
      - key: "node.kubernetes.io/instance-type"
        operator: In
        values: ["m5.large", "m5.xlarge"]
  ```

### **‚ö†Ô∏è Reliability Concerns**
- **Slow scaling may cause pod failures** if nodes aren‚Äôt provisioned fast enough.
- **Over-scaling increases costs unnecessarily**.

---

## **3Ô∏è‚É£ Check for Pod Disruption Budgets (PDBs)**

### **üîç How to Check**
```sh
kubectl get pdb -A
```
For detailed config:
```sh
kubectl describe pdb -n <namespace>
```

### **‚úÖ How to Improve**
- Define **PDBs to prevent too many disruptions**:
  ```yaml
  apiVersion: policy/v1
  kind: PodDisruptionBudget
  metadata:
    name: my-app-pdb
    namespace: my-namespace
  spec:
    minAvailable: 1
    selector:
      matchLabels:
        app: my-app
  ```

### **‚ö†Ô∏è Reliability Concerns**
- **Missing PDBs can cause mass pod evictions**.
- **Too strict PDBs (e.g., `minAvailable: 100%`) prevent node draining**.

---

## **4Ô∏è‚É£ Verify Ingress Configuration**

### **üîç How to Check**
```sh
kubectl get ingress -A
```
For detailed rules:
```sh
kubectl describe ingress <ingress-name> -n <namespace>
```

### **‚úÖ How to Improve**
- Ensure **Ingress is properly configured with an ALB**:
  ```yaml
  apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    name: my-app-ingress
    annotations:
      kubernetes.io/ingress.class: "alb"
  spec:
    rules:
      - host: my-app.example.com
        http:
          paths:
            - path: /
              pathType: Prefix
              backend:
                service:
                  name: my-app
                  port:
                    number: 80
  ```

### **‚ö†Ô∏è Reliability Concerns**
- **Misconfigured TLS certificates** can break traffic.
- **Missing health checks** may cause **traffic routing to failing pods**.

---

## **5Ô∏è‚É£ Validate Kyverno Policies**

### **üîç How to Check**
```sh
kubectl get clusterpolicies -A
kubectl get policies -A
```
For policy logs:
```sh
kubectl logs -l kyverno.io/component=kyverno
```

### **‚úÖ How to Improve**
- Ensure security policies like **image signing** and **enforcement of best practices**:
  ```yaml
  apiVersion: kyverno.io/v1
  kind: ClusterPolicy
  metadata:
    name: enforce-image-signing
  spec:
    validationFailureAction: Enforce
    rules:
      - name: check-image-signature
        match:
          resources:
            kinds:
              - Pod
        validate:
          message: "Container images must be signed"
  ```

### **‚ö†Ô∏è Reliability Concerns**
- **Too strict Kyverno policies can block deployments**.
- **Lack of policies exposes the cluster to security risks**.

---

## **6Ô∏è‚É£ Ensure Helm-Deployed OSS Components Are Properly Configured**

### **üîç How to Check**
```sh
helm list -A
helm get values <release-name> -n <namespace>
```

### **‚úÖ How to Improve**
- Ensure custom configurations are applied for **persistence, security, and monitoring**.

### **‚ö†Ô∏è Reliability Concerns**
- **Using default Helm values can lead to insecure setups**.
- **Misconfigured storage can lead to data loss**.

---

## **7Ô∏è‚É£ Verify GitLab and ArgoCD CI/CD Pipelines**

### **üîç How to Check GitLab Pipelines**
```sh
kubectl get pods -n gitlab
kubectl logs -n gitlab -l app=gitlab-runner
```

### **üîç How to Check ArgoCD Deployments**
```sh
kubectl get applications -n argocd
kubectl describe application <app-name> -n argocd
```

### **‚úÖ How to Improve**
- Ensure **GitLab CI/CD integrates with Kubernetes**.
- Ensure **ArgoCD syncs Git repositories automatically**.

### **‚ö†Ô∏è Reliability Concerns**
- **Pipeline failures can block releases**.
- **ArgoCD misconfiguration may lead to drift between Git and Kubernetes**.

---

## **üîü Additional Checks**
‚úÖ **Backup & Disaster Recovery (Velero)**
```sh
kubectl get backup -n velero
```
‚úÖ **AWS Secret Management**
```sh
aws secretsmanager list-secrets
```
‚úÖ **Certificate Expiry Monitoring**
```sh
kubectl get secret -A
```

---

üöÄ **This checklist ensures high availability, security, and resilience for Kubernetes workloads!**
